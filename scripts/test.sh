CUDA_VISIBLE_DEVICES=0,7 torchrun --standalone --nnodes 1 --nproc-per-node 2 train.py \
    --model llava_next_video \
    --llm llama3 \
    --dataset mix_pretrain \
    --max_txt_len 2048 \
    --num_temporal_tokens 300 \
    --num_frames 96 \
    --num_segs 12 \
    --stage pretrain \
    --epoch 1 \
    --mm_proj_lr 1e-5 \
    --lr 1e-3 \
    --warmup_ratio 0.03 \
    --lr_scheduler_type linear-warmup+cosine-decay \
    --sharding_strategy full-shard \
    --global_batch_size 256 \
    --per_device_batch_size 4 
